{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea70828-38b9-48db-a7f4-ec9c644bfc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import torch\n",
    "import os\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import langchain_community\n",
    "from ray.data import ActorPoolStrategy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from ray.data import from_pandas\n",
    "from functools import partial\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f380bee0-db3e-4c56-81b1-a827aca6d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8bcc10-7ce7-4337-91b3-99795848b21c",
   "metadata": {},
   "source": [
    "### Initializing Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bea217e-3ee8-4fe4-9c7a-511324db3215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 07:31:36,964\tINFO worker.py:1567 -- Connecting to existing Ray cluster at address: 10.10.2.206:6379...\n",
      "2024-04-02 07:31:36,977\tINFO worker.py:1743 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     obj = pickle.loads(in_band)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/storage.py\", line 371, in _load_from_bytes\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/serialization.py\", line 1040, in load\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/serialization.py\", line 1268, in _legacy_load\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     result = unpickler.load()\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/serialization.py\", line 1205, in persistent_load\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     wrap_storage=restore_location(obj, location),\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/serialization.py\", line 391, in default_restore_location\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     result = fn(storage, location)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/serialization.py\", line 266, in _cuda_deserialize\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     device = validate_cuda_device(location)\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m   File \"/home/ubuntu/miniconda3/envs/ray/lib/python3.9/site-packages/torch/serialization.py\", line 250, in validate_cuda_device\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m     raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "\u001b[36m(process_chunk pid=665906, ip=10.10.2.65)\u001b[0m RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "runtime_env = {\n",
    "    \"pip\": [\n",
    "        \"langchain-text-splitters\",\n",
    "        \"langchain_community\", \n",
    "        \"sentence_transformers\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(runtime_env=runtime_env)\n",
    "else:\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de246c8-44a7-4fc1-aeeb-86396be8588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verfügbare Ressourcen: {'CPU': 32.0, 'object_store_memory': 17882033356.0, 'memory': 40631812916.0, 'GPU': 4.0, 'accelerator_type:T4': 4.0, 'node:10.10.3.5': 1.0, 'node:10.10.3.72': 1.0, 'node:10.10.2.65': 1.0, 'node:10.10.2.206': 1.0, 'node:__internal_head__': 1.0}\n"
     ]
    }
   ],
   "source": [
    "available_resources = ray.available_resources()\n",
    "print(\"Verfügbare Ressourcen:\", available_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f12da1-fb93-4f7e-a083-140b47c01c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/pubmed/chunk/pubmed23n0046.jsonl',\n",
       " 'data/pubmed/chunk/pubmed23n0050.jsonl',\n",
       " 'data/pubmed/chunk/pubmed23n0003.jsonl',\n",
       " 'data/pubmed/chunk/pubmed23n0068.jsonl',\n",
       " 'data/pubmed/chunk/pubmed23n0010.jsonl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = \"data/pubmed/chunk/\"\n",
    "file_names = os.listdir(directory_path)\n",
    "file_paths = [os.path.join(directory_path, file_name) for file_name in file_names]\n",
    "jsonl_file_paths = [file_path for file_path in file_paths if file_path.endswith('.jsonl')]\n",
    "\n",
    "jsonl_file_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f5635-5790-4ebe-aa5e-9d40c79c0a8c",
   "metadata": {},
   "source": [
    "### Using only head node for embedding.\n",
    "\n",
    "Initializing BioBERT Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9604cd32-b93c-47a1-94fb-5cfe89fabbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "import torch\n",
    "\n",
    "class EmbedChunks:\n",
    "    def __init__(self, max_length=512):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Laden des vortrainierten BioBERT-Modells und Hinzufügen eines MEAN-Pooling-Layers\n",
    "        # Durchschnitt der Werte der Eingabemerkmale berechnet und als Ausgabe verwendet\n",
    "        word_embedding_model = models.Transformer('dmis-lab/biobert-v1.1', max_seq_length=self.max_length)\n",
    "        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                                       pooling_mode_mean_tokens=True,\n",
    "                                       pooling_mode_cls_token=False,\n",
    "                                       pooling_mode_max_tokens=False)\n",
    "\n",
    "        self.model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device=self.device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        contents = [item[\"content\"] for item in batch]\n",
    "        embeddings = self.model.encode(contents, batch_size=len(contents), show_progress_bar=False)\n",
    "        return [{\"id\": item[\"id\"], \"title\": item[\"title\"], \"content\": item[\"content\"], \"PMID\": item.get(\"PMID\", None), \"embeddings\": embedding.tolist()} for item, embedding in zip(batch, embeddings)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298cec9-539d-4c9c-8de3-fdcd49bdde71",
   "metadata": {},
   "source": [
    "Iterating through every JSONL file adding the attribute \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c8a49-1e6e-45ae-87f2-526eee4715d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pubmed/embedded/pubmed23n0117.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0118.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0182.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0143.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0167.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0170.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0152.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0101.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0115.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0114.jsonl has been successfully written to data/pubmed/embedded\n",
      "data/pubmed/embedded/pubmed23n0166.jsonl has been successfully written to data/pubmed/embedded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "embedder = EmbedChunks()\n",
    "\n",
    "# Definiere die Pfade für die Quell- und Zielverzeichnisse\n",
    "source_directory = Path('data/pubmed/chunk')\n",
    "target_directory = Path('data/pubmed/embedded')\n",
    "target_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iteriert durch jede Datei im Quellverzeichnis\n",
    "for file_name in os.listdir(source_directory):\n",
    "    if file_name.endswith('.jsonl'):\n",
    "        source_file = source_directory / file_name\n",
    "        target_file = target_directory / file_name\n",
    "\n",
    "        # Erstellt eine neue Datei im Zielverzeichnis\n",
    "        with open(target_file, 'w') as target:\n",
    "            with open(source_file, 'r') as source:\n",
    "                for line in source:\n",
    "                    # Jede Zeile ist ein JSON-Objekt\n",
    "                    item = json.loads(line)\n",
    "                    # Verarbeite das Item mit EmbedChunks\n",
    "                    embedded_item = embedder([item])[0]  # [0], weil embedder eine Liste zurückgibt\n",
    "                    # Schreibe das bearbeitete Objekt in die Zieldatei\n",
    "                    target.write(json.dumps(embedded_item) + '\\n')\n",
    "            print(f\"{target_file} has been successfully written to data/pubmed/embedded\")\n",
    "                    \n",
    "\n",
    "print(\"Alle Dateien wurden verarbeitet und gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a578e-e1ca-4204-8b4b-b26fc248e400",
   "metadata": {},
   "source": [
    "To improve performance we'll try to distribute the embedding process on the Ray cluster using 4 nodes with GPUs. With one node the embedding of 200 JSONL files took "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
