{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON Files: 100%|██████████| 11/11 [00:03<00:00,  3.46it/s]\n",
      "Aggregating PubMed IDs: 100%|██████████| 43188/43188 [00:00<00:00, 3379607.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the directories\n",
    "json_dir = '~/Dokumente/DATEN_RAG_PM4/trainings_sets'\n",
    "csv_dir = os.path.expanduser(json_dir + '/csv')  # Ensure the path is expanded to the user's home directory\n",
    "\n",
    "# Create the CSV directory if it doesn't exist\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "# Initialize a set to hold all unique PubMed IDs across files\n",
    "all_pubmed_ids = set()\n",
    "\n",
    "# List all JSON files in the directory\n",
    "json_files = [f for f in os.listdir(os.path.expanduser(json_dir)) if f.endswith('.json')]  # Ensure the path is expanded\n",
    "\n",
    "# Loop through files with a tqdm progress bar\n",
    "for json_file in tqdm(json_files, desc=\"Processing JSON Files\"):\n",
    "    json_path = os.path.join(os.path.expanduser(json_dir), json_file)\n",
    "    \n",
    "    # Load JSON content\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Initialize a set for this file's PubMed IDs\n",
    "    file_pubmed_ids = set()\n",
    "    \n",
    "    # Extract unique PubMed IDs from the 'questions' section\n",
    "    for question in data.get('questions', []):\n",
    "        documents = question.get('documents', [])\n",
    "        for url in documents:\n",
    "            pubmed_id = int(url.split('/')[-1])\n",
    "            file_pubmed_ids.add(pubmed_id)\n",
    "    \n",
    "    # Update the set of all PubMed IDs\n",
    "    all_pubmed_ids.update(file_pubmed_ids)\n",
    "    \n",
    "    # Save to DataFrame and CSV for this file\n",
    "    df = pd.DataFrame({'pubmedid': list(file_pubmed_ids)})\n",
    "    csv_filename = os.path.splitext(json_file)[0] + '.csv'\n",
    "    csv_path = os.path.join(csv_dir, csv_filename)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Convert the set to a list with tqdm progress\n",
    "all_pubmed_ids_list = list(tqdm(all_pubmed_ids, desc=\"Aggregating PubMed IDs\"))\n",
    "\n",
    "# Save all PubMed IDs to a DataFrame with an extra column and save to CSV\n",
    "all_pubmed_ids_df = pd.DataFrame({'pubmedid': all_pubmed_ids_list, 'enthalten_in_dataset': 0})\n",
    "complete_csv_path = os.path.join(csv_dir, 'csv_complete.csv')\n",
    "all_pubmed_ids_df.to_csv(complete_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we flag the pubmedids which are avaible in the questions and our data subset in the mongodb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of PubMed IDs with a 1: 2.373344447531722%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to your CSV files\n",
    "complete_csv_path = '~/Dokumente/DATEN_RAG_PM4/trainings_sets/csv/csv_complete.csv'\n",
    "rag_pubmed_csv_path = '~/Dokumente/DATEN_RAG_PM4/pubmedidsindataset/RAGPubMed.csv'\n",
    "matched_ids_csv_path = '~/Dokumente/DATEN_RAG_PM4/trainings_sets/csv/matched_pubmed_ids.csv'\n",
    "\n",
    "# Read the DataFrames\n",
    "complete_df = pd.read_csv(complete_csv_path)\n",
    "rag_pubmed_df = pd.read_csv(rag_pubmed_csv_path)\n",
    "\n",
    "# Convert PMID to integer if not already\n",
    "rag_pubmed_df['PMID'] = rag_pubmed_df['PMID'].astype(int)\n",
    "\n",
    "# Check for presence and update the column\n",
    "complete_df['enthalten_in_dataset'] = complete_df['pubmedid'].isin(rag_pubmed_df['PMID']).astype(int)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "complete_df.to_csv(complete_csv_path, index=False)\n",
    "\n",
    "# Extract the PubMed IDs that have a match (1 in the 'enthalten_in_dataset' column)\n",
    "matched_pubmed_ids = complete_df[complete_df['enthalten_in_dataset'] == 1]['pubmedid']\n",
    "\n",
    "# Save the matched PubMed IDs to a separate CSV file\n",
    "matched_pubmed_ids.to_csv(matched_ids_csv_path, index=False, header=['pubmedid'])\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage = (complete_df['enthalten_in_dataset'].sum() / len(complete_df)) * 100\n",
    "\n",
    "print(f\"Percentage of PubMed IDs with a 1: {percentage}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we extract each questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries saved: 3779\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directories\n",
    "json_dir = '~/Dokumente/DATEN_RAG_PM4/trainings_sets'\n",
    "matched_ids_csv_path = '~/Dokumente/DATEN_RAG_PM4/trainings_sets/csv/matched_pubmed_ids.csv'\n",
    "output_json_path = '~/Dokumente/DATEN_RAG_PM4/trainings_sets/total/all_questions_in_mongodb.json'\n",
    "\n",
    "# Read the matched PubMed IDs\n",
    "matched_ids_df = pd.read_csv(matched_ids_csv_path)\n",
    "matched_pubmed_ids = set(matched_ids_df['pubmedid'])\n",
    "\n",
    "# List all JSON files in the directory\n",
    "json_files = [f for f in os.listdir(os.path.expanduser(json_dir)) if f.endswith('.json')]\n",
    "\n",
    "# Initialize a list to hold entries that meet the criteria\n",
    "selected_entries = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(os.path.expanduser(json_dir), json_file)\n",
    "    \n",
    "    # Load JSON content\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Check each entry for matched PubMed IDs\n",
    "    for question in data.get('questions', []):\n",
    "        documents = question.get('documents', [])\n",
    "        pubmed_ids = [int(url.split('/')[-1]) for url in documents]\n",
    "        # Count how many PubMed IDs in this question are in the matched list\n",
    "        match_count = sum(id_ in matched_pubmed_ids for id_ in pubmed_ids)\n",
    "        # If at least one (or two) match(es), save the entire entry\n",
    "        if match_count >= 1:  # Change to `>= 2` if you need at least two matches\n",
    "            selected_entries.append(question)\n",
    "\n",
    "# Save the selected entries to a new JSON file\n",
    "with open(os.path.expanduser(output_json_path), 'w') as file:\n",
    "    json.dump({'questions': selected_entries}, file, indent=4)\n",
    "\n",
    "# Print the count of selected entries\n",
    "print(f\"Total entries saved: {len(selected_entries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in all JSON files: 30212\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory\n",
    "json_dir = '~/Dokumente/DATEN_RAG_PM4/trainings_sets'\n",
    "\n",
    "# Expand the user's home directory symbol\n",
    "json_dir_expanded = os.path.expanduser(json_dir)\n",
    "\n",
    "# List all JSON files in the directory except all_questions_in_mongodb.json\n",
    "json_files = [f for f in os.listdir(json_dir_expanded) if f.endswith('.json') and f != 'all_questions_in_mongodb.json']\n",
    "\n",
    "# Initialize a counter\n",
    "total_entries = 0\n",
    "\n",
    "# Loop through each JSON file and count the entries\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(json_dir_expanded, json_file)\n",
    "    \n",
    "    # Load JSON content\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        # Count the number of entries in the 'questions' list\n",
    "        total_entries += len(data.get('questions', []))\n",
    "\n",
    "# Print the total count of entries\n",
    "print(f\"Total entries in all JSON files: {total_entries}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
