{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we import some neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from RAG_evaluator import RAG_evaluator\n",
    "sys.path.append(\"../../rag_system/\")\n",
    "from med_rag import MedRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we define an experiment name, this name should ! uniqely! identify the experiemnal run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"experiment_5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we implement a running experiment by using rag system one two and three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'experiment_5' already exists at /home/ubuntu/questions_answers_data/experiment_results/experiment_5\n"
     ]
    }
   ],
   "source": [
    "# Base directory where the new folder will be created\n",
    "base_directory = \"/home/ubuntu/questions_answers_data/experiment_results\"\n",
    "# input directory, change if diffrent one is used\n",
    "question_input_dir = \"/home/ubuntu/questions_answers_data/MEDMCQA_data/train.json\"\n",
    "\n",
    "\n",
    "# Construct the path for the new experiment folder\n",
    "experiment_folder_path = os.path.join(base_directory, experiment_name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(experiment_folder_path):\n",
    "    os.makedirs(experiment_folder_path)\n",
    "    print(f\"Directory '{experiment_name}' created at {experiment_folder_path}\")\n",
    "else:\n",
    "    print(f\"Directory '{experiment_name}' already exists at {experiment_folder_path}\")\n",
    "\n",
    "# Construct the path for the JSON file\n",
    "output_path_retriever_1 = os.path.join(experiment_folder_path, \"result_ragver_1.json\")\n",
    "output_path_retriever_2 = os.path.join(experiment_folder_path, \"result_ragver_2.json\")\n",
    "output_path_retriever_3 = os.path.join(experiment_folder_path, \"result_ragver_3.json\")\n",
    "output_path_retriever_4 = os.path.join(experiment_folder_path, \"result_ragver_4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the 3 retriever types used in the RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retriever 1: BioBERT\n",
    "- Retriever 2: BM25\n",
    "- Retriever 3: Hybrid Retriever BM25 reranked with medCPT cross encoder\n",
    "- Retriever 4: medCPT Retriever with reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriever 1: BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_system = MedRAG(retriever=4, question_type=3)\n",
    "\n",
    "rag_type_1 = RAG_evaluator(\n",
    "    rag_model=rag_system,\n",
    "    path_to_question_json=question_input_dir,\n",
    "    output_path=output_path_retriever_4,\n",
    "    multiplechoice=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:   0%|          | 99/182822 [05:33<163:58:54,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'used_PMIDs'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:   0%|          | 100/182822 [05:40<172:49:20,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to /home/ubuntu/questions_answers_data/experiment_results/experiment_5/result_ragver_4.json\n",
      "Processing time: 341.63 seconds\n"
     ]
    }
   ],
   "source": [
    "rag_type_1.run_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for RAG with retriever 4\n",
      "Total Questions: 100\n",
      "\n",
      "Response Time:\n",
      "Mean: 3.37 seconds\n",
      "Standard Deviation: 0.93 seconds\n",
      "\n",
      "Summary of non answered questions:\n",
      "Absolute count - No Docs Found: 11\n",
      "Percentage - No Docs Found: 11.00%\n",
      "\n",
      "Classification Metrics:\n",
      "Accuracy: 0.48\n",
      "Recall: 0.48\n",
      "Precision: 0.55\n",
      "F1 Score: 0.50\n",
      "\n",
      "Additional metrics:\n",
      "Mean response time overall: 3.37\n",
      "Mean response time retriever: 2.29\n",
      "Mean response time generation: 1.08\n"
     ]
    }
   ],
   "source": [
    "rag_type_1.analyze_performance(\n",
    "    \"/home/ubuntu/questions_answers_data/experiment_results/experiment_5/result_ragver_4.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
